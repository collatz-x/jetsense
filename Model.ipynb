{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8822b81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 105,571 rows across 600 engines\n",
      "🧩 Features: 35 | Target: 'RUL'\n",
      "🧩 Split by engines → Train: 420, Val: 90, Test: 90\n",
      "\n",
      "🔹 MODEL 1: RIDGE REGRESSION (Regularized Linear)\n",
      "🏆 Best Ridge Alpha: 100.0\n",
      "📊 Ridge Regression (Val) → MAE: 13.318, RMSE: 17.507, R²: 0.892\n",
      "\n",
      "🔹 MODEL 2: RANDOM FOREST (GridSearch)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "🏆 Best Params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "📊 Random Forest (Val) → MAE: 12.875, RMSE: 18.164, R²: 0.884\n",
      "📊 Random Forest (Test) → MAE: 15.527, RMSE: 20.881, R²: 0.867\n",
      "\n",
      "============================================================\n",
      "🏁 SUMMARY\n",
      "Ridge Regression Val R²: 0.892\n",
      "Random Forest Val R²:     0.884\n",
      "Random Forest Test R²:    0.867\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# MODEL TRAINING PIPELINE (Ridge Regularization Version)\n",
    "# ==============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# LOAD GOLD DATA (from Parquet)\n",
    "# --------------------------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "feature_path = \"datamart/gold/feature_store.parquet\"\n",
    "label_path   = \"datamart/gold/label_store.parquet\"\n",
    "\n",
    "# Load Parquet files instead of CSVs\n",
    "df_feat = pd.read_parquet(feature_path)\n",
    "df_label = pd.read_parquet(label_path)\n",
    "\n",
    "# Ensure unit & cycle columns are aligned for merge\n",
    "if not all(col in df_feat.columns for col in [\"unit\", \"cycle\"]):\n",
    "    raise KeyError(\"Feature store missing required columns ['unit', 'cycle']\")\n",
    "if not all(col in df_label.columns for col in [\"unit\", \"cycle\"]):\n",
    "    raise KeyError(\"Label store missing required columns ['unit', 'cycle']\")\n",
    "\n",
    "# Merge features and labels on identifiers\n",
    "df = df_feat.merge(df_label, on=[\"unit\", \"cycle\"], how=\"inner\")\n",
    "\n",
    "print(f\"✅ Loaded {len(df):,} rows across {df['unit'].nunique()} engines\")\n",
    "print(f\"🧩 Features: {df_feat.shape[1]-2:,} | Target: 'RUL'\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# PREPARE FEATURES / LABELS\n",
    "# --------------------------------------------------------------\n",
    "drop_cols = [\"unit\", \"cycle\", \"RUL\"]\n",
    "X = df.drop(columns=drop_cols)\n",
    "y = df[\"RUL\"]\n",
    "units = df[\"unit\"]\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# SPLIT ENGINE-WISE (avoid leakage)\n",
    "# --------------------------------------------------------------\n",
    "np.random.seed(42)\n",
    "engine_ids = df[\"unit\"].unique()\n",
    "np.random.shuffle(engine_ids)\n",
    "\n",
    "n = len(engine_ids)\n",
    "train_cut = int(n * 0.7)\n",
    "val_cut   = int(n * 0.85)\n",
    "\n",
    "train_units = engine_ids[:train_cut]\n",
    "val_units   = engine_ids[train_cut:val_cut]\n",
    "test_units  = engine_ids[val_cut:]\n",
    "\n",
    "def subset(units_subset):\n",
    "    mask = df[\"unit\"].isin(units_subset)\n",
    "    return df.loc[mask, X.columns], df.loc[mask, \"RUL\"]\n",
    "\n",
    "X_train, y_train = subset(train_units)\n",
    "X_val, y_val     = subset(val_units)\n",
    "X_test, y_test   = subset(test_units)\n",
    "\n",
    "print(f\"🧩 Split by engines → Train: {len(train_units)}, Val: {len(val_units)}, Test: {len(test_units)}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# METRIC HELPER\n",
    "# --------------------------------------------------------------\n",
    "def evaluate(name, y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"📊 {name} → MAE: {mae:.3f}, RMSE: {rmse:.3f}, R²: {r2:.3f}\")\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# MODEL 1 — RIDGE REGRESSION (Regularized Linear)\n",
    "# --------------------------------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(\"\\n🔹 MODEL 1: RIDGE REGRESSION (Regularized Linear)\")\n",
    "\n",
    "ridge_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", Ridge())\n",
    "])\n",
    "\n",
    "param_grid_ridge = {\"ridge__alpha\": [0.1, 1.0, 10.0, 50.0, 100.0]}\n",
    "grid_ridge = GridSearchCV(\n",
    "    ridge_pipe,\n",
    "    param_grid_ridge,\n",
    "    scoring=\"r2\",\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "\n",
    "best_ridge = grid_ridge.best_estimator_\n",
    "print(f\"🏆 Best Ridge Alpha: {grid_ridge.best_params_['ridge__alpha']}\")\n",
    "\n",
    "pred_val_ridge = best_ridge.predict(X_val)\n",
    "mae_ridge, rmse_ridge, r2_ridge = evaluate(\"Ridge Regression (Val)\", y_val, pred_val_ridge)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# MODEL 2 — RANDOM FOREST (GridSearch)\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n🔹 MODEL 2: RANDOM FOREST (GridSearch)\")\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [10, 20, None],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "def rmse_scorer(y_true, y_pred):\n",
    "    return -sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(rmse_scorer),\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid.best_estimator_\n",
    "print(f\"🏆 Best Params: {grid.best_params_}\")\n",
    "\n",
    "pred_val_rf = best_rf.predict(X_val)\n",
    "mae_rf, rmse_rf, r2_rf = evaluate(\"Random Forest (Val)\", y_val, pred_val_rf)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# TEST EVALUATION\n",
    "# --------------------------------------------------------------\n",
    "pred_test_rf = best_rf.predict(X_test)\n",
    "mae_test, rmse_test, r2_test = evaluate(\"Random Forest (Test)\", y_test, pred_test_rf)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# SUMMARY\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n============================================================\")\n",
    "print(\"🏁 SUMMARY\")\n",
    "print(f\"Ridge Regression Val R²: {r2_ridge:.3f}\")\n",
    "print(f\"Random Forest Val R²:     {r2_rf:.3f}\")\n",
    "print(f\"Random Forest Test R²:    {r2_test:.3f}\")\n",
    "print(\"============================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "896ce189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Re-evaluating both models on TEST set...\n",
      "📊 Ridge Regression (Test) → MAE: 14.504, RMSE: 19.231, R²: 0.887\n",
      "📊 Random Forest (Test) → MAE: 15.527, RMSE: 20.881, R²: 0.867\n",
      "\n",
      "🏆 BEST MODEL SELECTED\n",
      "------------------------------------------------------------\n",
      "Model Type : RidgeRegression\n",
      "Val MAE     : 13.318\n",
      "Val RMSE    : 17.507\n",
      "Val R²      : 0.892\n",
      "Test MAE    : 14.504\n",
      "Test RMSE   : 19.231\n",
      "Test R²     : 0.887\n",
      "------------------------------------------------------------\n",
      "✅ Best model (RidgeRegression) saved successfully!\n",
      "💾 Model file     → model_bank/engine_rul_prediction_2025-11-02.pkl\n",
      "📘 Metadata file  → model_bank/engine_rul_prediction_2025-11-02_meta.json\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# SAVE BEST MODEL + RETEST BOTH ON TEST SET\n",
    "# ==============================================================\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n🔁 Re-evaluating both models on TEST set...\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1️⃣ Re-test Ridge Regression on test set\n",
    "# --------------------------------------------------------------\n",
    "pred_test_ridge = best_ridge.predict(X_test)\n",
    "mae_test_ridge, rmse_test_ridge, r2_test_ridge = evaluate(\"Ridge Regression (Test)\", y_test, pred_test_ridge)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2️⃣ Re-test Random Forest on test set\n",
    "# --------------------------------------------------------------\n",
    "pred_test_rf = best_rf.predict(X_test)\n",
    "mae_test_rf, rmse_test_rf, r2_test_rf = evaluate(\"Random Forest (Test)\", y_test, pred_test_rf)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3️⃣ Select best model based on validation R²\n",
    "# --------------------------------------------------------------\n",
    "if r2_rf >= r2_ridge:\n",
    "    best_model = best_rf\n",
    "    model_name = \"RandomForestRegressor\"\n",
    "    mae_val, rmse_val, r2_val = mae_rf, rmse_rf, r2_rf\n",
    "    mae_test, rmse_test, r2_test = mae_test_rf, rmse_test_rf, r2_test_rf\n",
    "else:\n",
    "    best_model = best_ridge\n",
    "    model_name = \"RidgeRegression\"\n",
    "    mae_val, rmse_val, r2_val = mae_ridge, rmse_ridge, r2_ridge\n",
    "    mae_test, rmse_test, r2_test = mae_test_ridge, rmse_test_ridge, r2_test_ridge\n",
    "\n",
    "print(\"\\n🏆 BEST MODEL SELECTED\")\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(f\"Model Type : {model_name}\")\n",
    "print(f\"Val MAE     : {mae_val:.3f}\")\n",
    "print(f\"Val RMSE    : {rmse_val:.3f}\")\n",
    "print(f\"Val R²      : {r2_val:.3f}\")\n",
    "print(f\"Test MAE    : {mae_test:.3f}\")\n",
    "print(f\"Test RMSE   : {rmse_test:.3f}\")\n",
    "print(f\"Test R²     : {r2_test:.3f}\")\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4️⃣ Save best model and metadata\n",
    "# --------------------------------------------------------------\n",
    "model_bank_directory = \"model_bank/\"\n",
    "os.makedirs(model_bank_directory, exist_ok=True)\n",
    "\n",
    "model_artefact = {\n",
    "    \"model_name\": model_name,\n",
    "    \"model_version\": f\"engine_rul_prediction_{datetime.now():%Y-%m-%d}\",\n",
    "    \"train_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"metrics\": {\n",
    "        \"Ridge\": {\n",
    "            \"Val\": {\"MAE\": mae_ridge, \"RMSE\": rmse_ridge, \"R2\": r2_ridge},\n",
    "            \"Test\": {\"MAE\": mae_test_ridge, \"RMSE\": rmse_test_ridge, \"R2\": r2_test_ridge},\n",
    "        },\n",
    "        \"RandomForest\": {\n",
    "            \"Val\": {\"MAE\": mae_rf, \"RMSE\": rmse_rf, \"R2\": r2_rf},\n",
    "            \"Test\": {\"MAE\": mae_test_rf, \"RMSE\": rmse_test_rf, \"R2\": r2_test_rf},\n",
    "        },\n",
    "        \"Selected\": {\n",
    "            \"Model\": model_name,\n",
    "            \"Val_R2\": r2_val,\n",
    "            \"Test_R2\": r2_test\n",
    "        }\n",
    "    },\n",
    "    \"features_used\": X.columns.tolist(),\n",
    "    \"train_size\": len(X_train),\n",
    "    \"val_size\": len(X_val),\n",
    "    \"test_size\": len(X_test),\n",
    "    \"random_seed\": 42\n",
    "}\n",
    "\n",
    "# Save model binary\n",
    "model_filename = os.path.join(model_bank_directory, model_artefact[\"model_version\"] + \".pkl\")\n",
    "with open(model_filename, \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Save metadata JSON\n",
    "artefact_filename = os.path.join(model_bank_directory, model_artefact[\"model_version\"] + \"_meta.json\")\n",
    "with open(artefact_filename, \"w\") as f:\n",
    "    json.dump(model_artefact, f, indent=4)\n",
    "\n",
    "print(f\"✅ Best model ({model_name}) saved successfully!\")\n",
    "print(f\"💾 Model file     → {model_filename}\")\n",
    "print(f\"📘 Metadata file  → {artefact_filename}\")\n",
    "print(\"------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48cab69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Loaded model artefact: RidgeRegression (engine_rul_prediction_2025-11-02)\n",
      "✅ Model loaded from model_bank/engine_rul_prediction_2025-11-02.pkl\n",
      "\n",
      "🚀 Generating OOT bootstrap from test set...\n",
      "📊 RidgeRegression (OOT) → MAE: 13.864, RMSE: 18.757, R²: 0.883\n",
      "\n",
      "✅ OOT results saved successfully!\n",
      "💾 Path: datamart/gold/oot_predictions_ridgeregression.parquet\n",
      "📊 RidgeRegression (OOT) → MAE: 13.864, RMSE: 18.757, R²: 0.883\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# OUT-OF-TIME (OOT) BOOTSTRAP USING BEST-SAVED MODEL\n",
    "# ==============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1️⃣ Load best model metadata\n",
    "# --------------------------------------------------------------\n",
    "# Latest artefact saved by model training\n",
    "model_bank_directory = \"model_bank/\"\n",
    "meta_files = sorted(\n",
    "    [f for f in os.listdir(model_bank_directory) if f.endswith(\"_meta.json\")],\n",
    "    reverse=True\n",
    ")\n",
    "if not meta_files:\n",
    "    raise FileNotFoundError(\"No model metadata found in model_bank/. Did you run model training?\")\n",
    "\n",
    "latest_meta_path = os.path.join(model_bank_directory, meta_files[0])\n",
    "with open(latest_meta_path, \"r\") as f:\n",
    "    model_artefact = json.load(f)\n",
    "\n",
    "model_name = model_artefact[\"model_name\"]\n",
    "model_version = model_artefact[\"model_version\"]\n",
    "print(f\"\\n📦 Loaded model artefact: {model_name} ({model_version})\")\n",
    "\n",
    "# Load the corresponding trained model (.pkl)\n",
    "model_file = os.path.join(model_bank_directory, model_version + \".pkl\")\n",
    "with open(model_file, \"rb\") as f:\n",
    "    best_model = pickle.load(f)\n",
    "print(f\"✅ Model loaded from {model_file}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2️⃣ Bootstrap OOT sample (from real test engines)\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n🚀 Generating OOT bootstrap from test set...\")\n",
    "\n",
    "test_units_unique = df.loc[df[\"unit\"].isin(test_units), \"unit\"].unique()\n",
    "n_oot = 90\n",
    "boot_units = np.random.choice(test_units_unique, size=n_oot, replace=True)\n",
    "oot_units = [f\"OOT_{i+1}\" for i in range(n_oot)]\n",
    "\n",
    "oot_list = []\n",
    "\n",
    "for new_id, base_unit in zip(oot_units, boot_units):\n",
    "    engine_df = df[df[\"unit\"] == base_unit].copy()\n",
    "    engine_df = engine_df.sort_values(\"cycle\").reset_index(drop=True)\n",
    "    engine_df = engine_df[[\"cycle\"] + X.columns.tolist() + [\"RUL\"]]\n",
    "    engine_df[\"unit\"] = new_id\n",
    "    oot_list.append(engine_df)\n",
    "\n",
    "oot_df = pd.concat(oot_list, ignore_index=True)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3️⃣ Predict using loaded best model\n",
    "# --------------------------------------------------------------\n",
    "oot_X = oot_df[X.columns]\n",
    "oot_y_true = oot_df[\"RUL\"]\n",
    "oot_df[\"RUL_pred\"] = best_model.predict(oot_X)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4️⃣ Evaluate performance\n",
    "# --------------------------------------------------------------\n",
    "mae_oot, rmse_oot, r2_oot = evaluate(f\"{model_name} (OOT)\", oot_y_true, oot_df[\"RUL_pred\"])\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5️⃣ Save results\n",
    "# --------------------------------------------------------------\n",
    "oot_path = f\"datamart/gold/oot_predictions_{model_name.lower()}.parquet\"\n",
    "os.makedirs(os.path.dirname(oot_path), exist_ok=True)\n",
    "oot_df.to_parquet(oot_path, index=False)\n",
    "\n",
    "print(\"\\n✅ OOT results saved successfully!\")\n",
    "print(f\"💾 Path: {oot_path}\")\n",
    "print(f\"📊 {model_name} (OOT) → MAE: {mae_oot:.3f}, RMSE: {rmse_oot:.3f}, R²: {r2_oot:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
