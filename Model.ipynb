{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822b81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 105,571 rows across 600 engines\n",
      "üß© Split by engines ‚Üí Train: 420, Val: 90, Test: 90\n",
      "\n",
      "üîπ MODEL 1: RIDGE REGRESSION (Regularized Linear)\n",
      "üèÜ Best Ridge Alpha: 100.0\n",
      "üìä Ridge Regression (Val) ‚Üí MAE: 14.078, RMSE: 18.244, R¬≤: 0.891\n",
      "\n",
      "üîπ MODEL 2: RANDOM FOREST (GridSearch)\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "üèÜ Best Params: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "üìä Random Forest (Val) ‚Üí MAE: 13.634, RMSE: 18.219, R¬≤: 0.892\n",
      "üìä Random Forest (Test) ‚Üí MAE: 17.176, RMSE: 24.853, R¬≤: 0.836\n",
      "\n",
      "============================================================\n",
      "üèÅ SUMMARY\n",
      "Ridge Regression Val R¬≤: 0.891\n",
      "Random Forest Val R¬≤:     0.892\n",
      "Random Forest Test R¬≤:    0.836\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# MODEL TRAINING PIPELINE (Ridge Regularization Version)\n",
    "# ==============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# LOAD GOLD DATA\n",
    "# --------------------------------------------------------------\n",
    "feature_path = \"datamart/gold/feature_store.csv\"\n",
    "label_path   = \"datamart/gold/label_store.csv\"\n",
    "df_feat = pd.read_csv(feature_path)\n",
    "df_label = pd.read_csv(label_path)\n",
    "\n",
    "# Merge on unit + cycle\n",
    "df = df_feat.merge(df_label, on=[\"unit\", \"cycle\"], how=\"inner\")\n",
    "print(f\"‚úÖ Loaded {len(df):,} rows across {df['unit'].nunique()} engines\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# PREPARE FEATURES / LABELS\n",
    "# --------------------------------------------------------------\n",
    "drop_cols = [\"unit\", \"cycle\", \"RUL\"]\n",
    "X = df.drop(columns=drop_cols)\n",
    "y = df[\"RUL\"]\n",
    "units = df[\"unit\"]\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# SPLIT ENGINE-WISE (avoid leakage)\n",
    "# --------------------------------------------------------------\n",
    "np.random.seed(42)\n",
    "engine_ids = df[\"unit\"].unique()\n",
    "np.random.shuffle(engine_ids)\n",
    "\n",
    "n = len(engine_ids)\n",
    "train_cut = int(n * 0.7)\n",
    "val_cut   = int(n * 0.85)\n",
    "\n",
    "train_units = engine_ids[:train_cut]\n",
    "val_units   = engine_ids[train_cut:val_cut]\n",
    "test_units  = engine_ids[val_cut:]\n",
    "\n",
    "def subset(units_subset):\n",
    "    mask = df[\"unit\"].isin(units_subset)\n",
    "    return df.loc[mask, X.columns], df.loc[mask, \"RUL\"]\n",
    "\n",
    "X_train, y_train = subset(train_units)\n",
    "X_val, y_val     = subset(val_units)\n",
    "X_test, y_test   = subset(test_units)\n",
    "\n",
    "print(f\"üß© Split by engines ‚Üí Train: {len(train_units)}, Val: {len(val_units)}, Test: {len(test_units)}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# METRIC HELPER\n",
    "# --------------------------------------------------------------\n",
    "def evaluate(name, y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"üìä {name} ‚Üí MAE: {mae:.3f}, RMSE: {rmse:.3f}, R¬≤: {r2:.3f}\")\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# MODEL 1 ‚Äî RIDGE REGRESSION (Regularized Linear)\n",
    "# --------------------------------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(\"\\nüîπ MODEL 1: RIDGE REGRESSION (Regularized Linear)\")\n",
    "\n",
    "ridge_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", Ridge())\n",
    "])\n",
    "\n",
    "param_grid_ridge = {\"ridge__alpha\": [0.1, 1.0, 10.0, 50.0, 100.0]}\n",
    "grid_ridge = GridSearchCV(\n",
    "    ridge_pipe,\n",
    "    param_grid_ridge,\n",
    "    scoring=\"r2\",\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "\n",
    "best_ridge = grid_ridge.best_estimator_\n",
    "print(f\"üèÜ Best Ridge Alpha: {grid_ridge.best_params_['ridge__alpha']}\")\n",
    "\n",
    "pred_val_ridge = best_ridge.predict(X_val)\n",
    "mae_ridge, rmse_ridge, r2_ridge = evaluate(\"Ridge Regression (Val)\", y_val, pred_val_ridge)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# MODEL 2 ‚Äî RANDOM FOREST (GridSearch)\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\nüîπ MODEL 2: RANDOM FOREST (GridSearch)\")\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [10, 20, None],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "def rmse_scorer(y_true, y_pred):\n",
    "    return -sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(rmse_scorer),\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid.best_estimator_\n",
    "print(f\"üèÜ Best Params: {grid.best_params_}\")\n",
    "\n",
    "pred_val_rf = best_rf.predict(X_val)\n",
    "mae_rf, rmse_rf, r2_rf = evaluate(\"Random Forest (Val)\", y_val, pred_val_rf)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# TEST EVALUATION\n",
    "# --------------------------------------------------------------\n",
    "pred_test_rf = best_rf.predict(X_test)\n",
    "mae_test, rmse_test, r2_test = evaluate(\"Random Forest (Test)\", y_test, pred_test_rf)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# SUMMARY\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n============================================================\")\n",
    "print(\"üèÅ SUMMARY\")\n",
    "print(f\"Ridge Regression Val R¬≤: {r2_ridge:.3f}\")\n",
    "print(f\"Random Forest Val R¬≤:     {r2_rf:.3f}\")\n",
    "print(f\"Random Forest Test R¬≤:    {r2_test:.3f}\")\n",
    "print(\"============================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e732be57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Random Forest (OOT) ‚Üí MAE: 19.689, RMSE: 29.872, R¬≤: 0.794\n",
      "\n",
      "‚úÖ OOT results saved to datamart/gold/oot_predictions_bootstrap.csv\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# OUT-OF-TIME (OOT) BOOTSTRAP FROM REAL ENGINE TRAJECTORIES\n",
    "# ==============================================================\n",
    "\n",
    "# 1Ô∏è‚É£ Identify unique engines in the test set\n",
    "test_units_unique = df.loc[df[\"unit\"].isin(test_units), \"unit\"].unique()\n",
    "\n",
    "# 2Ô∏è‚É£ Randomly sample 90 engines (with replacement)\n",
    "n_oot = 90\n",
    "boot_units = np.random.choice(test_units_unique, size=n_oot, replace=True)\n",
    "oot_units = [f\"OOT_{i+1}\" for i in range(n_oot)]\n",
    "\n",
    "oot_list = []\n",
    "\n",
    "for new_id, base_unit in zip(oot_units, boot_units):\n",
    "    # Extract that engine's real sequence\n",
    "    engine_df = df[df[\"unit\"] == base_unit].copy()\n",
    "    engine_df = engine_df.sort_values(\"cycle\").reset_index(drop=True)\n",
    "    # Keep only selected features (after VIF drop)\n",
    "    engine_df = engine_df[[\"cycle\"] + X.columns.tolist() + [\"RUL\"]]\n",
    "    engine_df[\"unit\"] = new_id\n",
    "    oot_list.append(engine_df)\n",
    "\n",
    "oot_df = pd.concat(oot_list, ignore_index=True)\n",
    "\n",
    "# 3Ô∏è‚É£ Rename for clarity\n",
    "oot_X = oot_df[X.columns]\n",
    "oot_y_true = oot_df[\"RUL\"]\n",
    "\n",
    "# 4Ô∏è‚É£ Predict using best model\n",
    "oot_df[\"RUL_pred\"] = best_rf.predict(oot_X)\n",
    "\n",
    "# 5Ô∏è‚É£ Evaluate\n",
    "mae_oot, rmse_oot, r2_oot = evaluate(\"Random Forest (OOT)\", oot_y_true, oot_df[\"RUL_pred\"])\n",
    "\n",
    "# 6Ô∏è‚É£ Save results\n",
    "oot_df.to_csv(\"datamart/gold/oot_predictions_bootstrap.csv\", index=False)\n",
    "print(\"\\n‚úÖ OOT results saved to datamart/gold/oot_predictions_bootstrap.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
