{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3fbdac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'engine_rul_prediction',\n",
      " 'model_train_date_str': '2025-11-01',\n",
      " 'models_directory': 'model_bank/',\n",
      " 'random_seed': 42,\n",
      " 'train_test_ratio': 0.8}\n",
      "\n",
      "üì¶ Loading Gold data...\n",
      "Loaded 20631 rows with 100 engines.\n",
      "\n",
      "Split by engine IDs:\n",
      "  ‚Üí Train engines: 80 | Test engines: 20\n",
      "  ‚Üí Train samples: 16561 | Test samples: 4070\n",
      "\n",
      "‚úÖ Scaling complete.\n",
      "\n",
      "üîπ Training Linear Regression Model...\n",
      "Linear Regression ‚Üí MAE: 23.449, RMSE: 36.932, R¬≤: 0.684\n",
      "\n",
      "üîπ Training SVR Model...\n",
      "SVR (RBF) ‚Üí MAE: 23.146, RMSE: 36.787, R¬≤: 0.686\n",
      "\n",
      "üèÜ Best Model Selected: SVR (RBF)\n",
      "   ‚Üí RMSE: 36.787, MAE: 23.146, R¬≤: 0.686\n",
      "\n",
      "‚úÖ Saved best model to: model_bank/engine_rul_prediction_2025-11-01.pkl\n",
      "\n",
      "‚úÖ Model reload check passed. Mean prediction: 101.78\n",
      "\n",
      "üìä FINAL MODEL PERFORMANCE SUMMARY\n",
      "{'MAE': 23.146113234911326,\n",
      " 'R2': 0.6860258979034353,\n",
      " 'RMSE': np.float64(36.78698968917228)}\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# MODEL TRAINING PIPELINE ‚Äî LINEAR REGRESSION & SVR (RUL PREDICTION)\n",
    "# ==============================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pprint\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ CONFIGURATION\n",
    "# --------------------------------------------------------------\n",
    "config = {}\n",
    "config[\"model_train_date_str\"] = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "config[\"train_test_ratio\"] = 0.8\n",
    "config[\"random_seed\"] = 42\n",
    "config[\"model_name\"] = \"engine_rul_prediction\"\n",
    "config[\"models_directory\"] = \"model_bank/\"\n",
    "\n",
    "pprint.pprint(config)\n",
    "\n",
    "np.random.seed(config[\"random_seed\"])\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ LOAD GOLD FEATURE & LABEL STORES (MERGED)\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\nüì¶ Loading Gold data...\")\n",
    "\n",
    "feature_path = \"datamart/gold/feature_store.parquet\"\n",
    "label_path = \"datamart/gold/label_store.parquet\"\n",
    "\n",
    "# Load both\n",
    "X_feat = pd.read_parquet(feature_path)\n",
    "y_df = pd.read_parquet(label_path)\n",
    "\n",
    "# Merge safely (aligning by index)\n",
    "df = X_feat.reset_index(drop=True).merge(y_df.reset_index(drop=True), left_index=True, right_index=True)\n",
    "\n",
    "print(f\"Loaded {len(df)} rows with {len(df['unit'].unique())} engines.\")\n",
    "\n",
    "# Separate features and target\n",
    "y = df[\"RUL\"]\n",
    "X = df.drop(columns=[\"RUL\"])\n",
    "\n",
    "# Optional NaN safeguard\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ TRAIN/TEST SPLIT (BY ENGINE UNIT ID)\n",
    "# --------------------------------------------------------------\n",
    "engine_ids = X[\"unit\"].unique()\n",
    "train_engines, test_engines = train_test_split(\n",
    "    engine_ids, test_size=0.2, random_state=config[\"random_seed\"]\n",
    ")\n",
    "\n",
    "X_train = X[X[\"unit\"].isin(train_engines)]\n",
    "X_test  = X[X[\"unit\"].isin(test_engines)]\n",
    "y_train = y[X[\"unit\"].isin(train_engines)]\n",
    "y_test  = y[X[\"unit\"].isin(test_engines)]\n",
    "\n",
    "print(f\"\\nSplit by engine IDs:\")\n",
    "print(f\"  ‚Üí Train engines: {len(train_engines)} | Test engines: {len(test_engines)}\")\n",
    "print(f\"  ‚Üí Train samples: {len(X_train)} | Test samples: {len(X_test)}\")\n",
    "\n",
    "# Drop non-feature columns before scaling\n",
    "drop_cols = [c for c in [\"unit\", \"cycle\", \"processing_timestamp\", \"op_regime\", \"early_life\"] if c in X_train.columns]\n",
    "X_train = X_train.drop(columns=drop_cols, errors=\"ignore\")\n",
    "X_test = X_test.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ DATA SCALING\n",
    "# --------------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n‚úÖ Scaling complete.\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5Ô∏è‚É£ TRAIN LINEAR REGRESSION MODEL\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\nüîπ Training Linear Regression Model...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict & evaluate\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Linear Regression ‚Üí MAE: {mae_lr:.3f}, RMSE: {rmse_lr:.3f}, R¬≤: {r2_lr:.3f}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6Ô∏è‚É£ TRAIN SVR MODEL\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\nüîπ Training SVR Model...\")\n",
    "svr_model = SVR(kernel=\"rbf\", C=10, epsilon=0.1)\n",
    "svr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict & evaluate\n",
    "y_pred_svr = svr_model.predict(X_test_scaled)\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "rmse_svr = np.sqrt(mean_squared_error(y_test, y_pred_svr))\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "\n",
    "print(f\"SVR (RBF) ‚Üí MAE: {mae_svr:.3f}, RMSE: {rmse_svr:.3f}, R¬≤: {r2_svr:.3f}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7Ô∏è‚É£ SELECT BEST MODEL (BASED ON RMSE)\n",
    "# --------------------------------------------------------------\n",
    "if rmse_svr < rmse_lr:\n",
    "    best_model = svr_model\n",
    "    best_name = \"SVR (RBF)\"\n",
    "    metrics = {\"MAE\": mae_svr, \"RMSE\": rmse_svr, \"R2\": r2_svr}\n",
    "else:\n",
    "    best_model = lr_model\n",
    "    best_name = \"Linear Regression\"\n",
    "    metrics = {\"MAE\": mae_lr, \"RMSE\": rmse_lr, \"R2\": r2_lr}\n",
    "\n",
    "print(f\"\\nüèÜ Best Model Selected: {best_name}\")\n",
    "print(f\"   ‚Üí RMSE: {metrics['RMSE']:.3f}, MAE: {metrics['MAE']:.3f}, R¬≤: {metrics['R2']:.3f}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 8Ô∏è‚É£ SAVE BEST MODEL ARTEFACT\n",
    "# --------------------------------------------------------------\n",
    "os.makedirs(config[\"models_directory\"], exist_ok=True)\n",
    "\n",
    "model_artefact = {\n",
    "    \"model_name\": best_name,\n",
    "    \"model_version\": f\"{config['model_name']}_{config['model_train_date_str']}\",\n",
    "    \"model\": best_model,\n",
    "    \"metrics\": metrics,\n",
    "    \"scaler\": scaler,\n",
    "    \"train_test_split\": {\n",
    "        \"train_engines\": train_engines.tolist(),\n",
    "        \"test_engines\": test_engines.tolist(),\n",
    "        \"train_ratio\": config[\"train_test_ratio\"]\n",
    "    },\n",
    "    \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "}\n",
    "\n",
    "file_path = os.path.join(\n",
    "    config[\"models_directory\"], model_artefact[\"model_version\"] + \".pkl\"\n",
    ")\n",
    "\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(model_artefact, f)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved best model to: {file_path}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 9Ô∏è‚É£ VALIDATE LOADED MODEL\n",
    "# --------------------------------------------------------------\n",
    "with open(file_path, \"rb\") as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "loaded_scaler = loaded_model[\"scaler\"]\n",
    "loaded_model_instance = loaded_model[\"model\"]\n",
    "\n",
    "y_pred_check = loaded_model_instance.predict(loaded_scaler.transform(X_test))\n",
    "print(f\"\\n‚úÖ Model reload check passed. Mean prediction: {np.mean(y_pred_check):.2f}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# üîü PRINT FINAL SUMMARY\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\nüìä FINAL MODEL PERFORMANCE SUMMARY\")\n",
    "pprint.pprint(model_artefact[\"metrics\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
